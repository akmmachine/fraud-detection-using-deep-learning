{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75502978-47f8-41ff-bfec-c0d6fdec9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2306d50-72ac-41e3-976c-14092c4bfaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfc_df = pd.read_csv(\"hdfc_dataset.csv\")\n",
    "sbi_df = pd.read_csv(\"sbi_dataset.csv\")\n",
    "df = pd.concat([hdfc_df, sbi_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd264ff7-95fc-40cf-b042-110f2c98d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df.drop(['Date', 'Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3d85c-fb3b-4e0a-9feb-a48b2c2c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "#columns ko sub columns me create kerke numerical check karega\n",
    "cat_cols = ['Merchant', 'Cardholder_Name', 'Transaction_Type', 'Device_Used', 'Location']\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c5c73-dbea-4e67-8105-2e243118ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing\n",
    "scaler = MinMaxScaler()\n",
    "df[['Amount']] = scaler.fit_transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4d7b3-25d1-4de2-9a6f-9a95487f2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder Part \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdf6ef-92f9-4bde-9f9a-d4630f64bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['Fraud_Label', 'Transaction_ID', 'Card_Number', 'IP_Address', 'Timestamp'], axis=1)\n",
    "labels = df['Fraud_Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f9bda-e48a-4a9a-b2c6-89a019437a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only non-fraud data for training the autoencoder\n",
    "X_train_ae = X_train[y_train == 0]  ## non fraud \n",
    "X_train_tensor = torch.tensor(X_train_ae.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2880cb-54d2-46b9-9b6a-0dd62dfb7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(input_dim, 8), nn.ReLU())\n",
    "        self.decoder = nn.Sequential(nn.Linear(8, input_dim), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x): #forward passing of x into encoder and decoder \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e5908e-b982-4bc5-9aa2-07d302e4aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Autoencoder\n",
    "model = Autoencoder(X_train_tensor.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33b5a6-2f6a-414d-841d-163ee2fd7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, X_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340050da-693f-4961-9435-c4fa8e17803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reconstruction error for test data\n",
    "reconstructions = model(X_test_tensor).detach().numpy()\n",
    "mse = np.mean(np.power(X_test.values - reconstructions, 2), axis=1)\n",
    "threshold = np.percentile(mse, 95)  # Set threshold at 95th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4bd4f-a13e-4336-a57d-34b867cd3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using threshold\n",
    "y_pred_ae = [1 if e > threshold else 0 for e in mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0c5c4-9c89-4f29-b2c5-95e0c0e5329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix (Autoencoder):\\n\", confusion_matrix(y_test, y_pred_ae))\n",
    "print(\"\\nClassification Report (Autoencoder):\\n\", classification_report(y_test, y_pred_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90c4be-5928-40d3-aafa-d4eecc58a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN PART \n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edf0c4-1044-45d6-ab64-4be1a1ed7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode graph-related attributes\n",
    "df_graph = df.copy()\n",
    "for col in ['Card_Number', 'Merchant', 'IP_Address']:\n",
    "    df_graph[col] = LabelEncoder().fit_transform(df_graph[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572dd4b-74b0-46f3-b252-ee5bcd06b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edges by connecting transactions sharing same Card_Number, Merchant, or IP_Address\n",
    "edges = set()\n",
    "for attr in ['Card_Number', 'Merchant', 'IP_Address']:\n",
    "    for val in df_graph[attr].unique():\n",
    "        idx = df_graph[df_graph[attr] == val].index.tolist()\n",
    "        for i in range(len(idx)):\n",
    "            for j in range(i + 1, len(idx)):\n",
    "                edges.add((idx[i], idx[j]))\n",
    "                edges.add((idx[j], idx[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efae698-cf1e-4f65-adc8-841f38c3c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PyTorch Geometric\n",
    "edge_index = torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n",
    "X_gnn = df_graph.drop(['Transaction_ID', 'Fraud_Label', 'Timestamp'], axis=1)\n",
    "X_gnn = torch.tensor(X_gnn.values, dtype=torch.float32)\n",
    "y_gnn = torch.tensor(df_graph['Fraud_Label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c75d1-1191-4ba4-9da4-78be919250c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X_gnn, edge_index=edge_index, y=y_gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4a81d-6d13-43e8-a221-fd8fb929988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173634a3-70ba-4cc5-8499-16287fee6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GCN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_gnn = GCN(data.num_node_features).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98372131-f64a-41c6-938a-6a64712383d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split for GNN\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "train_mask[:int(0.7 * data.num_nodes)] = True\n",
    "test_mask = ~train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65172c-173e-4c46-ae7c-ef863f4250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 101):\n",
    "    model_gnn.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model_gnn(data)\n",
    "    loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb726652-2249-48ee-9f7b-a5c5101e8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate GCN model\n",
    "model_gnn.eval()\n",
    "pred = model_gnn(data).argmax(dim=1)\n",
    "print(\"Confusion Matrix (GNN):\\n\", confusion_matrix(data.y[test_mask].cpu(), pred[test_mask].cpu()))\n",
    "print(\"\\nClassification Report (GNN):\\n\", classification_report(data.y[test_mask].cpu(), pred[test_mask].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e79829-da03-4f97-9afb-ef4998104b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73fccc-7d78-45b4-85b0-a6b23ccc0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder prediction\n",
    "def predict_autoencoder_with_reason(user_input):\n",
    "    input_df = pd.DataFrame([user_input])\n",
    "\n",
    "# Encode categorical values using pre-fitted label encoders\n",
    "    for col in encoders:\n",
    "        if user_input[col] not in encoders[col].classes_:\n",
    "            fallback = encoders[col].classes_[0]\n",
    "            print(f\" Unknown '{user_input[col]}' in '{col}' — using fallback: {fallback}\")\n",
    "            input_df[col] = encoders[col].transform([fallback])\n",
    "        else:\n",
    "            input_df[col] = encoders[col].transform([user_input[col]])\n",
    "\n",
    "    input_df[['Amount']] = scaler.transform(input_df[['Amount']])\n",
    "\n",
    "    input_tensor = torch.tensor(input_df.values, dtype=torch.float32)\n",
    "\n",
    "    model.eval()\n",
    "    output = model(input_tensor).detach().numpy()\n",
    "\n",
    " # Calculate the reconstruction error (absolute difference and MSE)\n",
    "    error_vector = np.abs(input_df.values - output)\n",
    "    total_error = np.mean(np.power(input_df.values - output, 2), axis=1)\n",
    "\n",
    "    prediction = \"FRAUDULENT\" if total_error > threshold else \"LEGITIMATE\"\n",
    "\n",
    " # Identify top 3 features contributing most to the reconstruction error\n",
    "    top_indices = error_vector[0].argsort()[-3:][::-1]\n",
    "    top_features = [input_df.columns[i] for i in top_indices]\n",
    "    top_contributions = error_vector[0][top_indices]\n",
    "\n",
    "    print(f\"\\n Autoencoder Prediction: {prediction}\")\n",
    "    print(f\" Total Reconstruction Error: {total_error[0]:.5f}\")\n",
    "    print(\"Top contributing features to anomaly:\")\n",
    "    for feat, val in zip(top_features, top_contributions):\n",
    "        print(f\"  - {feat}: error {val:.4f}\")\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f740f-586a-4c5a-abc1-72064fa9ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN- prediction with graph reasoning\n",
    "def predict_gnn_with_reason(new_txn_raw):\n",
    "    import copy\n",
    "    df_temp = copy.deepcopy(df_graph)  \n",
    "\n",
    " # Encode and inject the new transaction with synthetic IDs and timestamp\n",
    "    new_txn = {\n",
    "        \"Amount\": scaler.transform([[new_txn_raw[\"Amount\"]]])[0][0],\n",
    "        \"Merchant\": encoders[\"Merchant\"].transform([new_txn_raw[\"Merchant\"]])[0],\n",
    "        \"Cardholder_Name\": encoders[\"Cardholder_Name\"].transform([new_txn_raw[\"Cardholder_Name\"]])[0],\n",
    "        \"Transaction_Type\": encoders[\"Transaction_Type\"].transform([new_txn_raw[\"Transaction_Type\"]])[0],\n",
    "        \"Device_Used\": encoders[\"Device_Used\"].transform([new_txn_raw[\"Device_Used\"]])[0],\n",
    "        \"Location\": encoders[\"Location\"].transform([new_txn_raw[\"Location\"]])[0],\n",
    "        \"Card_Number\": 999999,\n",
    "        \"IP_Address\": 888888,\n",
    "        \"Fraud_Label\": 0,  \n",
    "        \"Transaction_ID\": 999999,\n",
    "        \"Timestamp\": pd.to_datetime(\"2025-01-01 00:00:00\")\n",
    "    }\n",
    "\n",
    " # Append the new transaction to the temp DataFrame\n",
    "    df_temp = pd.concat([df_temp, pd.DataFrame([new_txn])], ignore_index=True)\n",
    "\n",
    "    for col in ['Card_Number', 'Merchant', 'IP_Address']:\n",
    "        df_temp[col] = LabelEncoder().fit_transform(df_temp[col])\n",
    "\n",
    "# Check if new transaction shares connections with past frauds\n",
    "    fraud_neighbors = []\n",
    "    new_idx = df_temp.index[-1]\n",
    "\n",
    "    for attr in ['Card_Number', 'Merchant', 'IP_Address']:\n",
    "        matching = df_temp[(df_temp[attr] == df_temp.loc[new_idx, attr]) & (df_temp.index != new_idx)]\n",
    "        frauds = matching[matching['Fraud_Label'] == 1]\n",
    "        if not frauds.empty:\n",
    "            fraud_neighbors.append(attr)\n",
    "\n",
    " # Build edge list based on shared entities (link-based)\n",
    "    edges = set()\n",
    "    for attr in ['Card_Number', 'Merchant', 'IP_Address']:\n",
    "        for val in df_temp[attr].unique():\n",
    "            idxs = df_temp[df_temp[attr] == val].index.tolist()\n",
    "            for i in range(len(idxs)):\n",
    "                for j in range(i + 1, len(idxs)):\n",
    "                    edges.add((idxs[i], idxs[j]))\n",
    "                    edges.add((idxs[j], idxs[i]))\n",
    "\n",
    "# Convert edge list and features to tensors for PyTorch Geometric\n",
    "    edge_index = torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n",
    "    X_tensor = torch.tensor(df_temp.drop(['Transaction_ID', 'Fraud_Label', 'Timestamp'], axis=1).values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(df_temp['Fraud_Label'].values, dtype=torch.long)\n",
    "\n",
    "    data_input = Data(x=X_tensor, edge_index=edge_index, y=y_tensor).to(device)\n",
    "\n",
    "    model_gnn.eval()\n",
    "    pred = model_gnn(data_input).argmax(dim=1)\n",
    "    prediction = pred[-1].item() \n",
    "\n",
    "    result = \"FRAUDULENT\" if prediction == 1 else \"LEGITIMATE\"\n",
    "    print(f\"\\n GNN Prediction: {result}\")\n",
    "    if fraud_neighbors:\n",
    "        print(\" Connected to previous frauds via:\")\n",
    "        for attr in fraud_neighbors:\n",
    "            print(f\"  - Shared {attr}\")\n",
    "    else:\n",
    "        print(\" No direct links to known frauds.\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8ccab-89ef-4a7f-acf2-2ccc5db738f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_autoencoder_with_reason({\n",
    "    \"Amount\": 1200.00,\n",
    "    \"Merchant\": \"Amazon\",\n",
    "    \"Cardholder_Name\": \"Amit Singhr\",\n",
    "    \"Transaction_Type\": \"Online\",\n",
    "    \"Device_Used\": \"Mobile\",\n",
    "    \"Location\": \"Mumbai\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b31d9-0e10-4da7-a520-8459fd93f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_autoencoder_with_reason({\n",
    "    \"Amount\": 999990.00,\n",
    "    \"Merchant\": \"Amazon\",\n",
    "    \"Cardholder_Name\": \"Amit Singh\",\n",
    "    \"Transaction_Type\": \"Online\",\n",
    "    \"Device_Used\": \"Mobile\",\n",
    "    \"Location\": \"Mumbai\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e8326-6b8d-4ffc-b54b-03d33aa19c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gnn_with_reason({\n",
    "    \"Amount\": 200.60,\n",
    "    \"Merchant\": \"Uber\",\n",
    "    \"Cardholder_Name\": \"Vikas Verma\",\n",
    "    \"Transaction_Type\": \"Online\",\n",
    "    \"Device_Used\": \"Laptop\",\n",
    "    \"Location\": \"Delhi\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8051e2-fe2e-43f9-8749-d10114159dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of reconstruction errors with threshold line for anomaly detection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816b987-a3e0-4735-8730-80e6b783f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(mse, bins=50, color='orange', edgecolor='black')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.title(\" Reconstruction Error Distribution\")\n",
    "plt.xlabel(\"Reconstruction Error\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8582a2d6-52f4-4f23-b24c-7c70f5c59dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search and find fruad with maximum Reconstruction Error\n",
    "X_test_copy = X_test.copy()\n",
    "X_test_copy['Reconstruction_Error'] = mse\n",
    "X_test_copy['Actual_Label'] = y_test.values\n",
    "X_test_copy['Predicted_Label'] = y_pred_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e5efe-8d5f-45cf-a125-36f06f45e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frauds = X_test_copy.sort_values(by='Reconstruction_Error', ascending=False).head(10)\n",
    "top_frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e030e-9775-4e7c-91b6-cbdaca8a44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2354e-b75d-4ff6-b098-dc16d2fefe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_ae)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Autoencoder\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5cb746-3c4b-4095-b8b3-ab238c35508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40355ad3-52a8-4307-be72-55f582df1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_gnn.state_dict(), 'gnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0da7ef-74af-4b84-92ae-455a7cfe6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: plot_link_graph(df_graph)\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a95ea-aa9b-4006-88de-e752415e839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_link_graph(df_graph):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "\n",
    "    #Add each transaction as a node with label (fraud or legit)\n",
    "    for idx, row in df_graph.iterrows():\n",
    "        label = 'fraud' if row['Fraud_Label'] == 1 else 'legit'\n",
    "        G.add_node(idx, label=label)\n",
    "\n",
    "    #Define linking attributes for edge creation\n",
    "    link_attrs = ['Card_Number', 'Merchant', 'IP_Address']\n",
    "\n",
    "    \n",
    "    for attr in link_attrs:\n",
    "        values = df_graph[attr].unique()\n",
    "        for val in values:\n",
    "            idx_list = df_graph[df_graph[attr] == val].index.tolist()\n",
    "            for i in range(len(idx_list)):\n",
    "                for j in range(i + 1, len(idx_list)):\n",
    "                    G.add_edge(idx_list[i], idx_list[j], via=attr) \n",
    "\n",
    "    \n",
    "    colors = ['red' if G.nodes[n]['label'] == 'fraud' else 'green' for n in G.nodes]\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    pos = nx.spring_layout(G, seed=42, k=0.2) \n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=colors, node_size=50, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "\n",
    "    plt.title(\"🔗 Transaction Link Graph — Fraud (Red) vs Legit (Green)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc97b29-03c0-4835-abb3-d41149f74b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_link_graph(df_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fa171-87bc-4636-962a-c53d1411f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219986e1-f3d5-402e-b11c-a91440620bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(encoders, \"encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00b9d0-bd12-478d-84ea-879ae7324f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67cb4e-8c8b-43eb-ade7-c25f1c33552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Encoders and Scaler saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463f057-3bdf-4a0e-9f3f-514e3b9f77e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
